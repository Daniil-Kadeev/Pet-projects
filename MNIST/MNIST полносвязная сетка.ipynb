{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5073009f-e29b-47ef-a586-aef8d6a59059",
   "metadata": {},
   "source": [
    "# Нейронка класс своё MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c395104-dacc-4fea-a0fd-23b52819d06a",
   "metadata": {},
   "source": [
    "## Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68594406-3c1e-4a65-b382-2e59b1290785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import struct\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from os import path\n",
    "from array import array\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torchvision import transforms \n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59f416-d56e-4d4b-94db-217d5c9178d1",
   "metadata": {},
   "source": [
    "## Архитектура нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a7ce47-2d13-417d-8271-48d5ca9b8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self, input_, output):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_, 128)\n",
    "        self.layer2 = nn.Linear(128, output)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act(x)\n",
    "        out = self.layer2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a478d-47df-4eb2-9cde-154b0c1fb041",
   "metadata": {},
   "source": [
    "# Обязательная ячейка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41603fd3-5cf8-421c-a6da-3ab1074203cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_all_data = r'C:\\Users\\user\\Desktop\\learn models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9e4f1-e469-48b5-b825-d987524b4bfc",
   "metadata": {},
   "source": [
    "## Определение устройства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c1b6e-8451-464c-accb-627215b87965",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59160a-dc7a-45a2-87ac-c8bb4d8d0a0d",
   "metadata": {},
   "source": [
    "## Обработка изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f748da-fb4c-475e-be4c-b0510a3ed800",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.5, ), std=(0.5, ))    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e39b0f-1cf6-4690-95ba-d1ab4618affc",
   "metadata": {},
   "source": [
    "## Класс датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08cc82a-cae6-4993-a2d5-41188f5d0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset): # собственный класс для датасета\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.len_dataset = 0\n",
    "        self.data_list = [] # (путь до файла, позиция класса в ван хот векторе)\n",
    "        \n",
    "        for path_dir, dir_list, file_list in os.walk(path):\n",
    "            if path_dir == path:\n",
    "                self.classes = sorted(dir_list)\n",
    "                self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "                continue\n",
    "            cls = path_dir.split('\\\\')[-1]\n",
    "            for name_file in file_list:\n",
    "                file_path = os.path.join(path_dir, name_file)\n",
    "                self.data_list.append((file_path, self.class_to_idx[cls]))\n",
    "            self.len_dataset += len(file_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_dataset\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_path, target = self.data_list[index]\n",
    "        sample = Image.open(file_path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9cd91b-700f-4747-850b-e7691246f6f5",
   "metadata": {},
   "source": [
    "## Подгрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc228e69-c5d7-4b11-ab3b-acfe19c572b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNISTDataset(os.path.join(path_to_all_data, r'MNIST\\data\\training'), transform=transform)\n",
    "test_data = MNISTDataset(os.path.join(path_to_all_data, r'MNIST\\data\\testing'), transform=transform)\n",
    "for_one_hot_vector = MNISTDataset(os.path.join(path_to_all_data, r'MNIST\\data\\training'), transform=transform)\n",
    "\n",
    "train_data, val_data = random_split(train_data, [0.7, 0.3])\n",
    "\n",
    "# батчи\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f0070-8254-4b1c-ba4a-4c92775f9684",
   "metadata": {},
   "source": [
    "## Модель, гипер, шедуллер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd862d-eb71-4319-9ea4-3326aef30476",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNN(784, 10).to(device)\n",
    "\n",
    "loss_model = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001) # lr - скорость обучения\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, # оптимизатор\n",
    "                                                          mode='min', # max/min- следит чтобы отслеживаемый параметр увеличивался уменьшался\n",
    "                                                          factor=0.1, # коэф на который будет умножен lr\n",
    "                                                          patience=4, # кол-во эпох без улучшения отслеживаемого параметра\n",
    "                                                          threshold=0.0001, # порог на которой должен имениться отслеживаемый параметр\n",
    "                                                          threshold_mode='rel', # rel / abs. rel -отслеживаемый параметр должен измениться на threshhold% иначе просто\n",
    "                                                          cooldown=0, # кол-во перодов ожидания после уменьшения lr\n",
    "                                                          min_lr=0, # минимальное значение скорости обучения\n",
    "                                                          eps=1e-8 # минимальное изменение между новым и старым lr\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abcf2b3-c6d7-40a7-8bba-e19f304be7ac",
   "metadata": {},
   "source": [
    "## Предтрен списки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b4137-46bd-45e5-8ff3-1e9178fa9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "best_loss, train_loss, train_acc, val_loss, val_acc, lr_list, treshold = None, [], [], [], [], [], 0.00001\n",
    "count = 0 # число итераций без улучшения модели\n",
    "\n",
    "std_info = '''\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self, input_, output):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_, 128)\n",
    "        self.layer2 = nn.Linear(128, output)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act(x)\n",
    "        out = self.layer2(x)\n",
    "        return out\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9642a-f7e9-4a33-b339-495890de5ec8",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd9635-3eb7-4ae5-9334-fc5cd818a01e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Цикл обучения\n",
    "#     Тренировка модели\n",
    "#         Данные     \n",
    "#         Прямой проход и расчёт ошибки модели    \n",
    "#         Обратный проход\n",
    "#         Шаг оптимизации\n",
    "#     Расчёт метрики\n",
    "#     Сохранение лоса и метрики\n",
    "\n",
    "#     Валидация\n",
    "#         Данные     \n",
    "#         Прямой проход и расчёт ошибки модели            \n",
    "#     Расчёт метрики\n",
    "#     Сохранение лоса и метрики\n",
    "\n",
    "# цикл обучения\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # тренировка модели\n",
    "    model.train()\n",
    "    running_train_loss = []\n",
    "    true_answer = 0 # для подсчёта правильных ответов\n",
    "    train_loop = tqdm(train_loader, leave=False) # для когздания прогресс бара\n",
    "    for x, targets in train_loop:\n",
    "        # данные (batch_size, 1, 28, 28) -> (batch_size, 784)\n",
    "        x = x.reshape(-1, 28 * 28).to(device)\n",
    "        # (batch_size, int) -> (batch_size, 10), dtype=float32\n",
    "        targets = targets.reshape(-1).to(torch.int32) # делаем одномерный массив из нужных значений\n",
    "        targets = torch.eye(10)[targets].to(device) # из единичной матрицы 10*10 выдергиваем необходимые строки в соответствии с таргет\n",
    "\n",
    "        # прямой проход и расчет ошибки модели\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # обратный проход\n",
    "        opt.zero_grad() # обнуляем раннее вычесленный градиент\n",
    "        loss.backward() # производится обратный проход в результате которого получаются новые градиенты \n",
    "        # шаг оптимизации\n",
    "        opt.step() # корректировка весов\n",
    "\n",
    "        running_train_loss.append(loss.item()) # item - возвращает только значения функции потерь\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        train_loop.set_description(f'Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}')\n",
    "\n",
    "    \n",
    "    # расчёт значений метрики\n",
    "    running_train_acc = true_answer / len(train_data)\n",
    "    #сохранение значения функции потерь и метрики\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_acc)\n",
    "\n",
    "    # проверка модели - валидация\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # запрещаем вычисление градиента\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # данные (batch_size, 1, 28, 28) -> (batch_size, 784)\n",
    "            x = x.reshape(-1, 28 * 28).to(device)\n",
    "            # (batch_size, int) -> (batch_size, 10), dtype=float32\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(10)[targets].to(device)        \n",
    "\n",
    "\n",
    "            # прямой проход и расчет ошибки модели\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "            # val_loop.set_description(f'Epoch [{epoch+1}/{EPOCHS}], val_loss={mean_val_loss:.4f}')\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        # расчёт значений метрики\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "        #сохранение значения функции потерь и метрики\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "        # шаг шедуллера\n",
    "        lr_scheduler.step(mean_val_loss)\n",
    "        lr_list.append(lr_scheduler._last_lr[0])\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{EPOCHS}], train_loss={mean_train_loss:.4f}, train_acc={running_train_acc:.4f}, val_loss={mean_val_loss:.4f}, val_acc={running_val_acc:.4f}')\n",
    "\n",
    "        if best_loss is None:\n",
    "            best_loss = mean_val_loss\n",
    "\n",
    "        if mean_val_loss < best_loss - best_loss * treshold:\n",
    "            count = 0\n",
    "            best_loss = mean_val_loss\n",
    "            # torch.save(model.state_dict(), f'model_mnist/model_state_dict_epoch_{epoch}_mnist.pt')\n",
    "            checkpoint = {\n",
    "                        'class_to_idx': for_one_hot_vector.class_to_idx,\n",
    "                        'info': std_info,\n",
    "                        'state_model': model.state_dict(),\n",
    "                        'state_opt': opt.state_dict(),\n",
    "                        'state_lr_scheduler': lr_scheduler.state_dict(),\n",
    "                        'loss': {\n",
    "                            'train_loss': train_loss,\n",
    "                            'val_loss': val_loss,\n",
    "                            'best_loss': best_loss\n",
    "                        },\n",
    "                        'metric': {\n",
    "                            'train_acc': train_acc,\n",
    "                            'val_acc': val_acc\n",
    "                        },\n",
    "                        'lr': lr_list,\n",
    "                        'epoch': {\n",
    "                            'EPOCHS': EPOCHS,\n",
    "                            'save_epoch': epoch\n",
    "                        }\n",
    "                    }\n",
    "            torch.save(checkpoint, f'model_mnist/model_state_mnist_{epoch}_checkpoint.pt')\n",
    "            for i in os.listdir('model_mnist'):\n",
    "                if i == f'model_state_dict_epoch_{epoch}_mnist.pt' or i == f'model_mnist/model_state_mnist_{epoch}__checkpoint.pt':\n",
    "                    continue\n",
    "                os.remove(os.path.join(r'model_mnist', i))\n",
    "            print(f'На эпохе {epoch+1}, сохранена модель со значением функции потерь на валидации - {mean_val_loss:.4f}', end='\\n\\n')\n",
    "\n",
    "        if count >= 10:\n",
    "            print(f\"\\033[31mОбучение остановленно на {epoch + 1} эпохе.\\033[0m\")\n",
    "            break\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5bc31a-39ec-4403-82a7-ca8cba9ec606",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
